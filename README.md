# RAG-Powered LLM Agents for Banking Chatbots and Assistants

This repository contains the baseline solution for SMILES 2025 project focused on building a **Retrieval-Augmented Generation (RAG)** system for banking chatbots using Large Language Models (LLMs). The goal is to create an assistant capable of producing accurate and complete answers using Alfa-Bankâ€™s internal knowledge base.

---

## ğŸš€ Project Overview

### Scope

Participants are provided with:

- A **knowledge base** of articles describing Alfa-Bankâ€™s financial products (as `.txt` files)
- A **validation dataset**: pairs of *customer question â€“ reference answer*
- A **test set** of customer questions
- A **simple baseline solution** (this repo)

Your task is to develop a system that uses the provided documents to accurately respond to customer questions, optimizing answer quality.

### Why It Matters

Traditional rule-based chatbots are being replaced by intelligent LLM-driven assistants. However, LLMs do not have access to private, up-to-date data like banking product terms, making them unsuitable for real-world financial services without augmentation.

This project supports the industry shift toward **retrieval-augmented assistants**, and provides valuable hands-on experience in building production-grade LLM systems.

---

## ğŸ¯ Goals

- **Build an LLM-Based Chatbot**  
  Develop a chatbot using a retrieval-augmented pipeline and Alfa-Bankâ€™s internal knowledge base.

- **Optimize Answer Quality**  
  Improve the pipeline to achieve top performance on the METEOR metric.

- **Present Your Solution**  
  Deliver a clear report or presentation outlining your approach, innovations, and results.

---

## ğŸ“¦ Expected Deliverables

- âœ… Source code of the LLM-based assistant (e.g., this GitHub repo)
- âœ… A JSON file with generated answers to test set questions
- âœ… A report or slide deck summarizing your methodology and evaluation

---

## ğŸ“ Baseline Structure

### Files

- `baseline.py` â€” Loads the knowledge base and runs a BM25 + LLM (ChatGroq) retrieval-augmented QA system.
- `metrics.py` â€” Evaluates predictions using the **METEOR** metric.

### Key Components

- **Retriever**: BM25 (via `langchain_community.retrievers`)
- **LLM**: `gemma2-9b-it` served via Groq. You are free to use alternative LLMs and APIs.
- **Prompt**: Instructional prompt ensuring concise and grounded answers

---

### Run Baseline QA Generation

```bash
python3 baseline.py valid_dataset.json valid_predictions.json knowledge/
```

- `valid_dataset.json`: input JSON with customer queries
- `valid_predictions.json`: output file with predicted responses
- `knowledge/`: folder containing `.txt` documents used as the knowledge base

### Run Evaluation

```bash
python3 metrics.py valid_predictions.json
```

This will print the **average METEOR score** for the predicted answers.

---

## ğŸ“Š Metric

- The main evaluation metric is **METEOR**
- Reference answers are compared to model outputs
- The goal is to **maximize the METEOR score**

- The **main problem** is to generate answers that are **relevant**, **precise**, and **complete** based on the provided knowledge base.
- **METEOR** is used as a **proxy metric** to approximate answer quality. It compares generated responses to reference answers using lexical and semantic overlap.
- Participants may also use additional evaluation metrics that better capture factual correctness, completeness, or other qualitative aspects â€” especially if they highlight limitations in METEOR.
  
---

## ğŸ“š Dataset & Knowledge Base

Datasets are available: https://huggingface.co/datasets/mllab/smiles-2025

- `valid_dataset.json` â€” Validation examples with ground-truth responses
- `test_dataset.json` â€” Unlabeled questions for final evaluation
- `knowledge/` â€” Directory with knowledge base files in `.txt` format


---

## ğŸ“ Example

### Input JSON (`valid_dataset.json`)
```json
[
  {
    "query": "How can I apply for a mortgage?",
    "response": "You can apply for a mortgage through Alfa-Bank's online platform or by visiting a branch..."
  }
]
```

### Output JSON (`valid_predictions.json`)
```json
[
  {
    "query": "How can I apply for a mortgage?",
    "response": "You can apply for a mortgage through Alfa-Bank's online platform...",
    "pred_response": "You can apply for a mortgage on Alfa-Bankâ€™s website or in a local branch."
  }
]
```

---

## ğŸ§  Future Work

You can go beyond this baseline by:
- Improving retrieval quality
- Tuning prompts and model configuration
- Adding fallback mechanisms or filtering
- Using alternative LLMs methods

---

## ğŸ“© Contact

For questions or clarifications, please contact your project mentor (Telegram: @aaasenin).

---
